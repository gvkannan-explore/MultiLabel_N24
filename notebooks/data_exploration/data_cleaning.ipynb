{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "Cleaning the body, text and caption data for the tokenizer. The steps to be undertaken are listed below:\n",
    "* Remove extra whitespaces and normalizing the spaces.\n",
    "* Configure case normalization.\n",
    "* Handling special characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean text while preserving important punctuation and structure.\n",
    "    \"\"\"\n",
    "    # Replace multiple newlines/spaces with single space\n",
    "    text = re.sub(r\"\\n+\", \" \".text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    ## Replace multiple white-spaces with single space\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    ## Normalize quotes - Smart to regular quotes\n",
    "    text = text.replace('\"', '\"').replace('\"', '\"')\n",
    "\n",
    "    ## Normalize dashes -> to hyphen\n",
    "    text = text.replace(\"-\", \"-\").replace(\"â€“\", \"-\")\n",
    "\n",
    "    ## Fix spacing around punctuation.\n",
    "    text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\(\\s+\", \"(\", text)\n",
    "    text = re.sub(r\"\\s+\\)\", \")\", text)\n",
    "\n",
    "    ## Remove leading/trailing whitespace\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sentence(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split the text into sentences while handling common abbreviations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Common abbreviations to avoid splitting on\n",
    "    abbreviations = {\"mr.\", \"mrs.\", \"dr.\", \"st.\", \"ave.\", \"prof.\"}\n",
    "\n",
    "    # Split on sentence endings not part of abbreviations\n",
    "    sentences = []\n",
    "    current = []\n",
    "\n",
    "    words = text.split()  ## Splitting based on whitespaces\n",
    "    ## Iterate through each word until a stop character is found.\n",
    "    for word in words:\n",
    "        current.append(word)\n",
    "        if word.lower() in abbreviations:\n",
    "            continue\n",
    "        if word.endswith((\".\", \"!\", \"?\")):\n",
    "            sentences.append(\" \".join(current))\n",
    "            current = []\n",
    "\n",
    "    ## To add the last uncompleted sentence if any.\n",
    "    if current:\n",
    "        sentences.append(\" \".join(current))\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
